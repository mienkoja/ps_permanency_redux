---
title: "Parent Survey Reunification Analysis Redux"
output:
  pdf_document:
    toc: yes
  html_document:
    theme: cerulean
    toc: yes
  word_document: default
---

```{r preliminary, include=FALSE}
#load citation package and clear the bibliography
require(bibtex)
require(knitcitations)
newbib()
write.bib(c('RODBC', 'xtable', 'mstate', 'survival', 'reshape2', 'ggplot2', 'extrafont', 'pander', 'sqldf', 'ltm'), file="package.bib")
packbib <- read.bib("package.bib")
regbib <- read.bib("bibliography.bib")

#load the RODBC library
require(RODBC)
#make pretty tables
require(pander)
#handle multi-state data
require(mstate)
#load ggplot for plotting
require(ggplot2)
#load reshape for melting
require(reshape2)
#load POC colors, et al.
require(pocr)
#load nice fonts
require(extrafont)
#allow sql querying of data frames
require(sqldf)
#calculate IRT model
require(ltm)
#load lubridate to handle dates
require(lubridate)
```
# Overview

Our overall goal in this analysis is to examine the timing of permanency outcomes for the children of parents who were surveyed in a comprehensive survey of child-welfare involved parents in Washington State in 2008. Although the survey addressed parents who were served in-home and out-of-home, the analyses here will be limited to those parents who had at least one child placed in out-of-home care. This steps taken here will build toward a competing-risk event-history model.  

# Getting the Data

## Accessing the Original Survey Data

In order to solve a gap in institutional knowledge concerning the precise exclusion criteria used by prior POC staff, all available data files from the original SACWIS matches were exported to the POC2 SQL Server. The source files are in SPSS format and were exported using the SPSS database export utility over an ODBC connection. The source files are available to authorized POC analysts at the following path: 

`\\poc2\Practice Model\PARENT SURVEY I\Reunification Analysis_Parent Survey\Original Data Files\Matt`

All files with at least a `dcid` (parent id for the survey) and a `Person ID` (child id from SACWIS) were imported to the SQL server in `dbCoreAdministrativeTables` in a schema names `survey`. These files were then unioned into a single table `ps_tbl_children` using the following SQL script: 


        if object_id('dbo.ps_tbl_children') is not null 
          drop table dbo.ps_tbl_children
        
        select
          dcid
          ,id_prsn_child
          ,min(placement_date) placement_date 
        into dbo.ps_tbl_children 
        from(
        	select 
        		dcid
        		,person_id id_prsn_child
        		,placement_date
        	from 
        		dbo.ps_open_matt_match_back
        	union
        	select 
        		dcid
        		,id_prsn id_prsn_child
        		,coalesce(placement_date, place_start) placement_date
        	from 
        		dbo.ps_open_mtt_match_back_famlink_missed_36			
        	union
        	select 
        		study_id dcid
        		,person_id id_prsn_child
        		,placement_date
        	from 
        		dbo.ps_Original_Openwithplacements_BA_added	
        	union
        	select 
        		dcid
        		,id_prsn id_prsn_child
        		,place_start placement_date
        	from 
        		dbo.ps_still_open_match_back_from_famlink) tmp
        group by 
        	dcid
        	,id_prsn_child
        ) tmp


This provides us with a cross-walk between the `dcid` and `Person ID` (hereafter `id_prsn_child`) for further use in our analysis.

We next load the data from the parent survey itself. These data are available in another SPSS file located at the following path:  

`\\poc2\Practice Model\PARENT SURVEY I\Parent Data\Original Data\POC FINAL DATA.sav`

As with the files described above, we export the data from SPSS to SQL Server on POC2 using the SPSS database utility. The data are stored in a table named `ps_tbl_parent_data`. We can join the two tables together using a SQL script. Here, however, we will do this directly in R using the `RODBC` package by `r citet(packbib[1])`.

```{r select_overall, tidy=FALSE, cache=TRUE}
#assign a connection object
cn <- odbcConnect("POC")


#use the connection object to send a query to our database
dat1 <- sqlQuery(cn, 
                "select 
                  *
                  ,id_prsn_child
                from ps_tbl_parent_data tpd
                	join ps_tbl_children tc
                	on tpd.dcid=tc.dcid")

#count the number of parents
dat1_par <- length(unique(dat1$DCID))
dat1_par

#count the number of children
dat1_chi <- length(unique(dat1$id_prsn_child))
dat1_chi
```

We can see from the above counts that the numbers are somewhat less than what are reported in other [POC documents](https://docs.google.com/viewer?url=http%3A%2F%2Fpartnersforourchildren.org%2Fsites%2Fdefault%2Ffiles%2Fpublications%2F2009._part_iv_baseline_parent_survey_analysis.pdf). Specifically, the link in the previous sentence shows a report in which POC reports to have completed surveys for 464 out-of-home cases. While this is true, only `r dat1_par` of these cases were able to be linked to an actual out-of-home placement using the original methodology. 

## Linking data to an actual removal record

The original methodology involved manually linking some survey records to placement dates in the SACWIS. While this may increase the overall number of linkages, it decreases replicability when the linking method cannot be scripted. Furthermore, as we are interested in building an event-history model with time-varying covariates (e.g. engagement), it is important that we have a clear linking strategy to ensure that we are only examining survey responses of parents who had a child in out-of-home care at the time of their interview.  

As such, we re-link the `id_prsn_child` fields from the `r dat1_par` records using the code shown below. In this code, we first write a common table expression to select the first `id_removal_episode_fact` within the 365 days preceding the parent's interview. We then use this id to select a complete set of records including all parent survey data (`ps_tbl_parent_data`) and all data from the `rptPlacements` base working table.


```{r select_reasonable_matches, tidy=FALSE, cache=TRUE}
dat2 <- sqlQuery(cn, 
                "with child_rem_id (dcid, id_prsn_child, id_removal_episode_fact) 
                as
                (
                select
                  tpd.dcid
                  ,tc.id_prsn_child
                  ,min(id_removal_episode_fact) id_removal_episode_fact
                from 
                	dbo.ps_tbl_parent_data tpd
                		join dbo.ps_tbl_children tc
                			on tpd.dcid=tc.dcid
        						join vw_episodes vep
        							on vep.eps_begin <= tpd.intdate 
        								and vep.eps_begin >= dateadd(dd, -365, tpd.intdate)
                        				and vep.id_prsn_child=tc.id_prsn_child
                        group by 
                        	tpd.dcid
                        	,tc.id_prsn_child
                        )
                        select distinct
        					cri.id_prsn_child
                        	,cri.id_removal_episode_fact 
        					--check for records of dependency from AOC data
        					--for any dependency date that takes place after permanency, set date to null
        					,case 
        						when datediff(dd
                                  ,isnull(vep.petition_dependency_date
                                          ,vep.eps_begin)
                                  ,isnull(vep.earlier_of_eps_end_18th_bday
                                          ,'2013-12-31')) < 0
        						then null
        						else vep.petition_dependency_date
        					end dep_date
        					--calculate the timing of court involvement 
        					,case 
        						--check for petitions before removal and set time to 0
        						when 
        							datediff(dd
                              ,vep.eps_begin
                              ,isnull(vep.petition_dependency_date
                                      ,vep.eps_begin)) < 0 
        						then 
        							0
        						--treat missing dependency dates (from logic above) with dur_days 
                    --greater than 365 as immediate dependencies
        						when 
        							case 
        							
        								when datediff(dd
                                      ,isnull(vep.petition_dependency_date
                                              ,vep.eps_begin)
                                      ,isnull(vep.earlier_of_eps_end_18th_bday
                                              ,'2013-12-31')) < 0
        								then null
        								else vep.petition_dependency_date
        							end is null 
        							and 
        							dur_days > 365
        						then 
        							0
        						--treat missing dependency dates with dur_days less than 365 as VPA cases
        						when 
        							case 	
        								when datediff(dd
                                      ,isnull(vep.petition_dependency_date
                                              ,vep.eps_begin)
                                      ,isnull(vep.earlier_of_eps_end_18th_bday
                                              ,'2013-12-31')) < 0
        								then null
        								else vep.petition_dependency_date
        							end is null 
        						then 
        							dur_days
        						--check for petitions after permanency and set time to episode duration
        						when
        							datediff(dd
                                ,vep.petition_dependency_date
                                ,isnull(vep.earlier_of_eps_end_18th_bday
                                        ,'2013-12-31')) < 0
        						then 
        							dur_days
        						--for all other cases just calculate the time from 
                    --eps_begin to the AOC petition 
        						else 
        							datediff(dd
                              ,vep.eps_begin
                              ,isnull(vep.petition_dependency_date
                                      ,vep.eps_begin))
        					end crt_t
        					,case 
        						--check for petitions before removal and flag as court involvement
        						when 
        							datediff(dd
                              ,vep.eps_begin
                              ,isnull(vep.petition_dependency_date
                                      ,vep.eps_begin)) < 0 
        						then 
        							1
        						--treat missing dependency dates (from logic above) with 
                    --dur_days greater than 365 as immediate dependencies
        						when 
        							case 
        								when datediff(dd
                                      ,isnull(vep.petition_dependency_date
                                              ,vep.eps_begin)
                                      ,isnull(vep.earlier_of_eps_end_18th_bday
                                              ,'2013-12-31')) < 0
        								then null
        								else vep.petition_dependency_date
        							end is null 
        							and 
        							dur_days > 365
        						then 
        							1
        						--treat missing dependency dates with dur_days less than 365 as VPA cases
        						when 
        							case 
        								when datediff(dd
                                      ,vep.petition_dependency_date
                                      ,isnull(vep.earlier_of_eps_end_18th_bday
                                              ,'2013-12-31')) < 0
        								then null
        								else vep.petition_dependency_date
        							end is null 
        						then 
        							0
        						--check for petitions after permanency and set time to episode duration
                    --(effectively VPAs)
        						when
        							datediff(dd
                              ,vep.petition_dependency_date
                              ,isnull(vep.earlier_of_eps_end_18th_bday
                                      ,'2013-12-31')) < 0
        						then 
        							0
        						--for all other cases just calculate the time from eps_begin to the 
                    --AOC or CA petition 
        						else 
        							1
        					end crt_s
        					,dur_days reu_t
        					,case
        						when outcome = 'Reunification' then 1 else 0
        					end reu_s
        					,dur_days adt_t
        					,case
        						when outcome = 'Adoption' then 1 else 0
        					end adt_s
        					,dur_days gdn_t
        					,case
        						when outcome = 'Guardianship' then 1 else 0
        					end gdn_s
  						    ,datediff(dd, vep.eps_begin, tpd.intdate) time_to_int
        					,tpd.* 
                  ,vep.*
                        from
                        	dbo.ps_tbl_parent_data tpd
                        		join child_rem_id cri
                        			on tpd.dcid=cri.dcid
        						join vw_episodes vep
        							on vep.id_removal_episode_fact = cri.id_removal_episode_fact
        				order by vep.id_removal_episode_fact")

#count the number of parents
dat2_par <- length(unique(dat2$DCID))
dat2_par

#count the number of children
dat2_chi <- length(unique(dat2$id_prsn_child))
dat2_chi
```


```{r}

dat2$time_to_rnt <- difftime(dat2$nxt_eps_date, dat2$eps_end, units = "days")

dat2$reentry_within_1yr <- ifelse(dat2$time_to_rnt > 365 | is.na(dat2$nxt_eps_date) == TRUE, 0, 1)

table(dat2$reu_s)
xtabs(dat2$reu_s ~ dat2$reentry_within_1yr)

dat2$employ <- ifelse(dat2$EMPSTAT < 1, NA, ifelse(dat2$EMPSTAT != 1, 1, 0))

xtabs(dat2$reentry_within_1yr ~ dat2$employ + dat2$reu_s)

model <- glm(reentry_within_1yr ~ employ, family="binomial", data=dat2[dat2$reu_s==1,])

predict(model, newdata=data.frame(employ=c(0,1)), type="response" )


library(survival)

#coxph(Surv(time_to_rnt))
```

As can be seen, we are left with `r dat2_par`  parents and `r dat2_chi`  children. To be clear, there are other `id_removal_episode_fact` matches for the original matches of children. However, the removal episodes for these children are either over 1 year before the interview date or after the interview date. We are thus left with administrative data matches for approximately `r 100*round(dat2_par/dat1_par, 2)` percent of the surveyed families who were identified as out-of-home care cases. 

# Excluding Subjects by Case Characteristics

The child welfare system in Washington engages families in an extremely heterogeneous manner. One of the major distinctions between out-of-home care cases is the extent to which children are engaged by the court system. Some children enter out-of-home (OOH) care by way of a voluntary placement agreement (VPA), some children enter OOH care by way of a court order, and some begin their stay in OOH in a VPA and then transition to placement under a court order. Identifying these children is important as the path they take through the system significantly impacts their probability of exiting the system at any given time `r citep("10.1016/j.childyouth.2012.08.004")`. In our initial match of survey data above, we created a new variable called `crt_s` which indicated the extent to which a child had any court involvement in their dependency^1^. 

```{r count_court_cases, results='asis', cache=TRUE, echo=FALSE}
pander(table(factor(dat2$crt_s,levels=c(0,1),labels=c("No Court", "Court")), dnn="Count"))
```

As can be seen there are 53 children who had no court involvement in their case. While event history models are flexible enough to include children who started in a VPA "state" and then transitions to either court involvement or some form of permanency, (see `r citet("10.1002/sim.2712")` for a review of this approach), the relatively small number of children starting in this state will not likely yield meaningful results. Including them in our analysis may, however, bias the results of our analysis of court-involved children. As such, these children will be excluded from our analysis. 

Our study also includes a small number of children who, at the time of our last observation, had experienced either no permanency outcome or had experienced an outcome classified as "other". 

```{r count_odd_outcomes, results='asis', echo=FALSE, cache=TRUE}
pander(table(dat2$outcome, dnn="Count"), split.table = Inf)
```

While event history methods certainly provide for the ability to handle such observations (mainly through identifying the children as right-censored as described by `r citet("10.2307/2529941")`), we are also interested in estimating the probability that children will not exit the system (i.e. the probability that they will "age-out" of care). While child welfare scholars typically treat these children as right-censored to observation in analyses, it is of substantive interest to determine the probability that children will age-out of care. In a multi-state approach to permanency outcomes, an analyst could include an additional "age-out" state in their model and derive a probability from this analysis. This approach, however, would make the implicit (and erroneous) assumption that children are at a constant risk of transitioning to the "age-out" state. While children are (in principle) at a constant risk of exiting to a given permanency outcome, they cannot age-out of care until they reach the age of majority. By excluding the small number of children who are still in care as of our last observation and children who have exited to a permanency type of "Other" (i.e. children who we would have traditionally treated as right censored), we will be freed to calculate a probability of aging out through simple arithmetic as shown below.

The small chunk of code below further subsets our data to children who exited to permanency by the end of 2013 and who had court involvement in their placement. 

```{r final_data_subset}
dat3 <- subset(dat2, !(dat2$outcome %in% c("Still in Care", "Other")) & dat2$crt_s == 1)
#count the number of parents
dat3_par <- length(unique(dat3$DCID))
dat3_par

#count the number of children
dat3_chi <- length(unique(dat3$id_prsn_child))
dat3_chi
```

The resulting sample includes `r dat3_par`  parents and `r dat3_chi`  children.

# Reviewing our Data

To begin reviewing the data, the first thing we want to do is get a sense of the outcomes for the `r dat3_chi`children. This will be accomplished through the use of the `mstate` package as described by `r citet("10.1016/j.cmpb.2010.01.001")`. 

## Prepare Data

In order to make use of the `mstate` package, there are a couple of preliminary steps that need to be taken:

1. Add a day to all values of time that we have^2. 
2. Define a transition matrix using `transMat()`.
3. Create an `msdata` `data.frame` using `msprep()`. 

```{r prep_data_for_mstate, tidy=FALSE, cache=TRUE}

dat3$crt_t_mod <- dat3$crt_t + 1
dat3$reu_t_mod <- dat3$reu_t + 1
dat3$adt_t_mod <- dat3$adt_t + 1
dat3$gdn_t_mod <- dat3$gdn_t + 1

tmat <- transMat(x = list(c(2,3,4)
                          ,c()
                          ,c()
                          ,c())
                 ,names = c("plc"
                           ,"reu"
                           ,"adt"
                           ,"gdn"))
tmat

ms_dat3 <- msprep(data=dat3
                  ,trans=tmat
                  ,time = c(NA
                            ,"reu_t_mod"
                            ,"adt_t_mod"
                            ,"gdn_t_mod")
                  ,status = c(NA
                            ,"reu_s"
                            ,"adt_s"
                            ,"gdn_s")
                  )
```


## Examine Data 
### Outcomes

The `events()` function allows us to see the proportion of children transitioning into each state (i.e. outcome) in our model. Of note is the "no-event" proportion. Based on the manner in which we subset our data above, this is precisely the proportion (0.07) who age-out of the system. Of note, there are no proportions indicates in the bottom three rows of the transition matrix, this is because Reunification, Adoption, and Guardianship are absorbing states in this model - for the purposes of this analysis, you cannot transition out of these states. 

```{r examine_events, cache=TRUE}
event_prop <- events(ms_dat3)$Proportions
colnames(event_prop) <- c("Placement in OOH","Reunification","Adoption","Guardianship","No Event")
rownames(event_prop) <- c("Placement in OOH","Reunification","Adoption","Guardianship")
```

```{r print_table_of_events, results='asis', echo=FALSE, cache=TRUE}
pander(ifelse(is.nan(event_prop), "", round(as.numeric(event_prop), 2)), split.table = Inf)
```

In addition to just knowing the overall probability of transitions, it is also helpful for us examine how these probabilities vary over the course of a child's stay in OOH care. We will ultimately want to know how such trends vary as a function of covariates. To start, however, we can simply estimate a non-parametric cox-model which will allow us to estimate the transition intensity (i.e. hazard rate) from placement in OOH care $(g)$ to one of our three identified permanency states $(h_k)$. Where  $k \in K$ and $K=\{r, a, g\}$ for transitions to reunification, adoption, and guardianship respectively. For this simple model, we make use of the `coxph()` function of the `survival` package by `r citet(packbib[6])`. As can be seen, `coxph()` can receive a set of data formatted with `mstate`. The transitions are specified by passing the `trans` variable to the `strata()` function. To be clear, the use of the `strata()` function simply makes additional calculations easier to accomplish. We could estimate three separate models (i.e. one for each transition) and the results would be identical to those obtained in this section of the document. Indeed, as we add more complexity to our model below, we will need to estimate separate models for each transition. 

```{r non_par_cox}
m0 <- coxph(Surv(Tstart, Tstop, status) ~ strata(trans), data = ms_dat3, method = "breslow")
```

Having estimated out non-parametric model, we will utilize the `msfit` function which estimates cumulative transition hazards $(\hat{A}_{gh_k}(t))$ for the transition for $g \rightarrow h_k$ at an event-time $(t)$ and the co-variances of each pair of estimated variances for a given value of $t$. 

```{r msfit}
msf_m0 <- msfit(object = m0, vartype = "greenwood", trans = tmat)
```

The information contained within `msf_m0` can now be used to calculate a matrix of estimated transition probabilities $(\mathbf{\hat{P}}(s,t))$ (as opposed to transition intensities) along $g \rightarrow h_k$ over the time interval $(s,t]$.

```{r prob_mat}
ptr_m0 <- probtrans(msf_m0, predt = 0, method = "greenwood")
```

There are several ways in which one might examine information in the transition probability matrix. One of the more helpful approaches is to "stack" transition probability curves for each transition (including the probability of a child remaining in care). This is accomplished by extracting the relevant data from our probability matrix and then defining a series of new curves (`pstate1_st`, `pstate2_st`, `pstate3_st`, and `pstate4_st`) with each subsequent curve being a cumulative sum of all previous curves. We then "melt" the data with the `reshape2` package by `r citet(packbib[8])` and reorder the different transition categories for use with the `geom_area()` function in the `ggplot2` package by `r citet(packbib[9])`. We also apply some more tasteful fonts using the `extrafonts` package `r citep(packbib[10])`. 

```{r prob_mat_stack}
ptr_m0_plot <- ptr_m0[[1]][,1:5]
ptr_m0_plot$pstate1_st <- ptr_m0_plot$pstate1
ptr_m0_plot$pstate2_st <- ptr_m0_plot$pstate1 + ptr_m0_plot$pstate2
ptr_m0_plot$pstate3_st <- ptr_m0_plot$pstate2_st + ptr_m0_plot$pstate3
ptr_m0_plot$pstate4_st <- ptr_m0_plot$pstate3_st + ptr_m0_plot$pstate4
ptr_m0_plot <- melt(ptr_m0_plot, id.vars="time")
ptr_m0_plot$variable <- reorder(ptr_m0_plot$variable, X = ptr_m0_plot$value, FUN= function(x) {- mean(x)})
```

Now that the the data are properly formatted, we plot the stacked transition probabilities with the code below.  

```{r prob_mat_stack_plot, fig.width=6, fig.height=6}

vars_plot <- c("time", "pstate1_st", "pstate2_st", "pstate3_st", "pstate4_st")

ggplot(subset(ptr_m0_plot, ptr_m0_plot$variable %in% vars_plot)
       ,aes(x=time/365.25, y=value, colour=variable)) +
      geom_area(position="identity"
                ,aes(x=time/365.25,y=value, fill = variable)
                ,alpha=.75
                ,show_guide=FALSE) +
      annotate("text"
               ,x = 1.25
               ,y = .25
               ,label = "Still in Care"
               ,face="bold"
               ,size=6
               ,family="Frutiger LT Std 45 Light"
               ,colour="#8d609d") +
      annotate("text"
               ,x = 3.75
               ,y = .4
               ,label = "Reunification"
               ,face="bold"
               ,size=6
               ,family="Frutiger LT Std 45 Light"
               ,colour="#32a5ba") +
      annotate("text"
               ,x = 4.15
               ,y = .77
               ,label = "Adoption"
               ,face="bold"
               ,size=6
               ,family="Frutiger LT Std 45 Light"
               ,colour="#6f8a64") +
      annotate("text"
               ,x = 4.15
               ,y = .95
               ,label = "Guardianship"
               ,face="bold"
               ,size=6
               ,family="Frutiger LT Std 45 Light"
               ,colour="#356380") +
      scale_colour_manual(values=poc_colors) +
      scale_fill_manual(values=poc_colors
                        ,guide = guide_legend(title = NULL)) +
      xlab("Years in Care") +
      ylab("Probability") +
      theme_bw() +
      theme(text=element_text(size=16
                              ,family="Frutiger LT Std 45 Light"))
```

As stated, the graph shown above demonstrates the stacked transition probabilities for each outcome in our data. The distance between two curves at any given point in time can be interpreted as the probability that a child will be in that state at that particular time. As is common throughout the US, we see that, throughout the last 5 years, children in our sample have a much larger probability of transitioning to reunification than any other permanency outcome. This trend remains true even after children begin transitioning to guardianship or adoption. We also see that, even having restricted our sample to court-involved children, some children begin experiencing transitions to reunification almost immediately while children do not have a substantive probability of transitioning to adoption or guardianship until 1 to 2 years of OOH care. 

An interesting aspect of the data presented here is the curve for those children still in OOH care. Given the manner in which we subset our data (i.e. the only right-censored observations in our data are for children who aged-out of the system), this curve represents the decreasing unbiased probability of aging-out of the system. Two features of this curve are worth mentioning: 1) That the curve decreases at a relatively constant rate, and 2) That the curve extends to a value of zero^2^. This does not mean that all children eventually exit to a form of permanency other than aging-out. As shown in the previous table, approximately 7% of children in our sample do age-out. Furthermore, although the chart certainly suggests that no children are "growing-up" in foster care, some of the children aging out do spend a long period of time in OOH care. We can see the difference in stay using the following chart comparing the survival curves of children aging out with the curves of all other children. 

```{r write_surv_tbl_fnc, cache=TRUE}
surv_tbl <- function(x){
  surv_tbl <- data.frame(time = x$time
                         ,surv = x$surv
                         ,strata = rep(names(x$strata), x$strata))
  return(surv_tbl)
} 
```

```{r examine_age_outs, fig.width=8, fig.height=6}
AO <- ifelse(dat3$outcome=="Age of Majority/Emancipation", 1, 0)
sf <- survfit(Surv(dat3$reu_t_mod, rep(1, length(dat3$reu_t_mod))) ~ AO)

ggplot(surv_tbl(sf), aes(y=surv, x=time/365.25, colour=strata)) + 
  geom_line(size=2) +
  scale_colour_manual(values=poc_colors
                      ,name = "Transition Type"
                      ,labels = c("Other Permanency", "Age-Out")) +
  xlab("Years in Care") +
  ylab("Probability of Transition") +
  theme_bw() +
  theme(text=element_text(size=16
                          ,family="Frutiger LT Std 45 Light"))

mh_test <- survdiff(Surv(dat3$reu_t_mod, rep(1, length(dat3$reu_t_mod))) ~ AO)
```


There is a clear visual difference between the two survival curves. Further examination reveals that the Kaplan-Meier estimate of the median for children exiting to some form of permanency is lower (656 days with a 95% confidence interval suggesting that the true values is between 594 and 683 days) than the estimated median for children aging-out of care (926 days with a 95% confidence interval suggesting true values to be between 711 and 1276). The results of a Mantel-Haenszel rank test (as implemented by `r citet("10.1093/biomet/69.3.553")`) yield a test statistic $\chi^2_{MH}=`r round(mh_test$chisq,2)`$ with $p < 0.0001$ indicating a significant difference between the two curves. This brief discussion about a child's probability of aging-out calls attention to a feature of child welfare data that is often ignored in the peer-reviewed literature. In essence, a child's probability of aging-out can be calculated as the $1-P(r \cup a \cup g)$ where $P(r \cup a \cup g)$ is the probability of the mutually exclusive permanency outcomes in $K$ as defined above^2^. 

#Branch off here and start running multinomial logistic per conversation with Mark and Maureen. 

#This first work here is serving a dual purpose of helping me with my R demo for SSWR


```{r try_logit_prep}
# this is the file that I am dumping to github for the SSWR workshop
# the simulation approach above does not pan out for the counterfactual graph I 
# am trying to produce

write.csv(dat3, file = "dat.csv", fileEncoding = "macroman")


#get rid of "unobserved outcomes" and rename
dat3$outcome <- as.factor(as.character(dat3$outcome)) 
levels(dat3$outcome) <- c("Adoption", "Emancipation", "Guardianship", "Reunification")

#assign reference cat of age_out
require(nnet)
require(MASS)
require(simcf)
#data(gator)
levels(dat3$outcome) <- c("Adoption"
                         ,"Emancipation"
                         ,"Guardianship"
                         ,"Reunification")

dat3$outcome_rl <- relevel(dat3$outcome, ref = "Emancipation")

#looking at age of child at episode begin
require(ggplot2)
ggplot(dat3, aes(x=age_eps_begin)) + 
  geom_histogram(binwidth = 1)

#looking at age of child at episode begin by outcome 
ggplot(dat3, aes(x=age_eps_begin, fill=outcome)) + 
  geom_histogram(binwidth = 1) +
  facet_wrap(~ outcome)

# run the multinomial model
model <- multinom(outcome_rl ~ age_eps_begin + 
                   eps_rank 
                 ,data = dat3
                 ,Hess = TRUE)

#extract params
pe <- model$wts[c(6,7,8,10,11,12,14,15,16)]

#run the multinomial model
vc <- solve(model$Hess) 

#load a package which contains a multivariate normal 
#sampling function
require(MASS)
#assign a variable for the number of simulations
sims <- 10000
#draw the indicates number of beta simulates 
#using our extracted model data
simbetas <- mvrnorm(sims,pe,vc)

simb <- array(NA, dim = c(sims,3,3))
simb[,,1] <- simbetas[,1:3]         
simb[,,2] <- simbetas[,4:6]
simb[,,3] <- simbetas[,7:9]
   

agerange <- seq(0,17,by=0.1)    

require(simcf)
xhyp <- cfFactorial(age = agerange
                    ,ep_rank = mean(dat3$eps_rank))

test_sims <- mlogitsimev(xhyp,simb,ci=0.95)

y <- as.vector(test_sims$pe[,1:4])

x <- rep(1:length(agerange), 4)

lower <- as.vector(test_sims$lower[,1:4,])

upper <- as.vector(test_sims$upper[,1:4,])

Outcome <- c(rep("Adoption", length(agerange))
                 ,rep("Guardianship"
                      ,length(agerange))
                 ,rep("Reunification"
                      ,length(agerange))
                 ,rep("Emancipation"
                      ,length(agerange)))

dat_sim_plot <- data.frame(y,x,lower,upper,Outcome)

p2 <- ggplot(dat_sim_plot
       ,aes(x=x/10, y=y, group=Outcome)) + 
        geom_line(size=1, alpha=.5) +
        geom_ribbon(aes(ymin=lower
                        ,ymax=upper
                        ,fill=Outcome), alpha=.5) +
        ylab("Pr(Outcome|Age,Prior Episodes)") +
        xlab("Age at Entry into Foster Care") +
        theme_bw() 

p2

```


## Back to Modeling

The above effort was just a demo for my SSWR 2015 workshop which shows how to model counterfactuals using a multinomial logistic regression model. 

We now return to the development of a more sophisticated model by way of BMA. 

```{r select_covariates}

#add outcome for emancipation 
dat3$emc_s <- ifelse(dat3$reu_s + dat3$adt_s + dat3$gdn_s == 1, 0, 1)

#prep covariates
dat3$log_age_eps_begin <- log1p(dat3$age_eps_begin)
dat3$ad_chld <- ifelse(dat3$age_eps_begin > 11, 1, 0)  
dat3$sm_chld <- ifelse(dat3$age_eps_begin <= 3, 1, 0) 
dat3$non_min <- ifelse(dat3$cd_race_census == 5, 1, 0)
dat3$male <- ifelse(dat3$cd_gndr == "M", 1, 0)
dat3$par_age <- year(strptime(dat3$eps_begin, format = "%Y-%m-%d"))-year(strptime(dat3$DOB, format = "%Y-%m-%d"))
dat3$log_par_age <- log(dat3$par_age)
dat3$married <- ifelse(dat3$MARSTAT < 1, NA, ifelse(dat3$MARSTAT == 2, 1, 0))
dat3$hhnum_c <- ifelse(dat3$CHTOTNUM < 1, NA, dat3$CHTOTNUM)
dat3$rel_plc <- ifelse(as.numeric(dat3$longest_plcm_setng)==3,1,0)
dat3$eps_rank <- dat3$eps_rank
dat3$log_eps_rank <- log(dat3$eps_rank)

dat3$housing_hs_cnt <- ifelse(is.na(dat3$LACRENT) == TRUE | dat3$LACRENT == 2, 0, 1) +
                        ifelse(is.na(dat3$EVICT) == TRUE | dat3$EVICT == 2, 0, 1) + 
                        ifelse(is.na(dat3$FAMFRND) == TRUE | dat3$FAMFRND == 2, 0, 1) + 
                        ifelse(is.na(dat3$REPOSS) == TRUE | dat3$REPOSS == 2, 0, 1) + 
                        ifelse(is.na(dat3$HOMLSS) == TRUE | dat3$HOMLSS == 2, 0, 1) 
dat3$hsg_hds <- ifelse(dat3$housing_hs_cnt > 0, 1, 0)
dat3$high_in <- ifelse(dat3$THHINC < 1, NA, ifelse(dat3$THHINC > 1, 1, 0))
dat3$sm_coll <- ifelse(dat3$EDULVL < 1, NA, ifelse(dat3$EDULVL > 3, 1, 0))
dat3$employ <- ifelse(dat3$EMPSTAT < 1, NA, ifelse(dat3$EMPSTAT != 1, 1, 0))


dat3$y2 = ifelse(dat3$YENG2 < 1, NA, dat3$YENG2)
dat3$y3 = ifelse(dat3$YENG3 < 1, NA, dat3$YENG3)
dat3$y7 = ifelse(dat3$YENG7 < 1, NA, dat3$YENG7)
dat3$y15 = ifelse(dat3$YENG15 < 1, NA, dat3$YENG15)
dat3$y5 = ifelse(dat3$YENG5 < 1, NA, dat3$YENG5)
dat3$y9 = ifelse(dat3$YENG9 < 1, NA, dat3$YENG9)
dat3$y11 = ifelse(dat3$YENG11 < 1, NA, dat3$YENG11)
dat3$y16 = ifelse(dat3$YENG16 < 1, NA, dat3$YENG16)
dat3$y6 = ifelse(dat3$YENG6 < 1, NA, dat3$YENG6)
dat3$y12 = ifelse(dat3$YENG12 < 1, NA, dat3$YENG12)
dat3$y19 = ifelse(dat3$YENG18 < 1, NA, dat3$YENG18)
dat3$y1 = ifelse(dat3$YENG1 < 1, NA, dat3$YENG1)
dat3$y4 = ifelse(dat3$YENG4 < 1, NA, dat3$YENG4)
dat3$y8 = ifelse(dat3$YENG8 < 1, NA, dat3$YENG8)
dat3$y10 = ifelse(dat3$YENG10 < 1, NA, dat3$YENG10)
dat3$y13 = ifelse(dat3$YENG13 < 1, NA, dat3$YENG13)
dat3$y14 = ifelse(dat3$YENG14 < 1, NA, dat3$YENG14)
dat3$y17 = ifelse(dat3$YENG19 < 1, NA, dat3$YENG19)
dat3$y18 = ifelse(dat3$YENG17 < 1, NA, dat3$YENG17)

#transform our variables
#linear
require(stringr)
var_tx_lin <- dat3[,c(351:369)] - 3
nam <- names(var_tx_lin)
names(var_tx_lin) <- str_c(nam, '_lin')
#signed square transform
var_tx_sgnsq <- sign(var_tx_lin) * abs(var_tx_lin)^2
names(var_tx_sgnsq) <- str_c(nam, '_signsq')
#signed square root transform
var_tx_sgnsqrt <- sign(var_tx_lin) * sqrt(abs(var_tx_lin))
names(var_tx_sgnsqrt) <- str_c(nam, '_signsqrt')
#ternary transform
var_tx_tern <- lapply(dat3[,c(351:369)]
                      ,function(x) as.numeric(as.character(cut(x
                                       ,breaks = c(0,2,3,5)
                                       ,labels=c(-1,0,1)
                                       )))
                      )
var_tx_tern <- as.data.frame(var_tx_tern)
names(var_tx_tern) <- str_c(nam, '_tern')

dat3$y2_fac = as.factor(ifelse(dat3$YENG2 < 1, NA, dat3$YENG2))
dat3$y3_fac = as.factor(ifelse(dat3$YENG3 < 1, NA, dat3$YENG3))
dat3$y7_fac = as.factor(ifelse(dat3$YENG7 < 1, NA, dat3$YENG7))
dat3$y15_fac = as.factor(ifelse(dat3$YENG15 < 1, NA, dat3$YENG15))
dat3$y5_fac = as.factor(ifelse(dat3$YENG5 < 1, NA, dat3$YENG5))
dat3$y9_fac = as.factor(ifelse(dat3$YENG9 < 1, NA, dat3$YENG9))
dat3$y11_fac = as.factor(ifelse(dat3$YENG11 < 1, NA, dat3$YENG11))
dat3$y16_fac = as.factor(ifelse(dat3$YENG16 < 1, NA, dat3$YENG16))
dat3$y6_fac = as.factor(ifelse(dat3$YENG6 < 1, NA, dat3$YENG6))
dat3$y12_fac = as.factor(ifelse(dat3$YENG12 < 1, NA, dat3$YENG12))
dat3$y19_fac = as.factor(ifelse(dat3$YENG18 < 1, NA, dat3$YENG18))
dat3$y1_fac = as.factor(ifelse(dat3$YENG1 < 1, NA, dat3$YENG1))
dat3$y4_fac = as.factor(ifelse(dat3$YENG4 < 1, NA, dat3$YENG4))
dat3$y8_fac = as.factor(ifelse(dat3$YENG8 < 1, NA, dat3$YENG8))
dat3$y10_fac = as.factor(ifelse(dat3$YENG10 < 1, NA, dat3$YENG10))
dat3$y13_fac = as.factor(ifelse(dat3$YENG13 < 1, NA, dat3$YENG13))
dat3$y14_fac = as.factor(ifelse(dat3$YENG14 < 1, NA, dat3$YENG14))
dat3$y17_fac = as.factor(ifelse(dat3$YENG19 < 1, NA, dat3$YENG19))
dat3$y18_fac = as.factor(ifelse(dat3$YENG17 < 1, NA, dat3$YENG17))

#reverse code for averaging
dat3$y3 = ifelse(dat3$YENG3 < 1, NA, -dat3$YENG3+6) 
dat3$y5 = ifelse(dat3$YENG5 < 1, NA, -dat3$YENG5+6)
dat3$y16 = ifelse(dat3$YENG16 < 1, NA, -dat3$YENG16+6)
dat3$y6 = ifelse(dat3$YENG6 < 1, NA, -dat3$YENG6+6)


dat3$rec <- rowMeans(dat3[,c(351:354)])
dat3$wrk <- rowMeans(dat3[,c(355:358)])
dat3$mis <- rowMeans(dat3[,c(359:361)])
dat3$buy <- rowMeans(dat3[,c(362:369)])
dat3$eng <- rowMeans(dat3[,c(351:369)])



dat3_reu <- cbind(reu_s = dat3$reu_s
                  ,var_tx_tern
                  ,var_tx_sgnsq
                  ,var_tx_sgnsqrt
                  ,var_tx_lin
                  ,dat3[,c(370:388)]
                  ,rec = dat3$rec
                  ,wrk = dat3$wrk
                  ,mis = dat3$mis
                  ,buy = dat3$buy
                  ,eng = dat3$eng
                  ,dat3[,c(351:369)])

dat3_reu <- na.omit(dat3_reu)

dat3_adt <- cbind(adt_s = dat3$adt_s
                  ,var_tx_tern
                  ,var_tx_sgnsq
                  ,var_tx_sgnsqrt
                  ,var_tx_lin
                  ,dat3[,c(370:388)]
                  ,rec = dat3$rec
                  ,wrk = dat3$wrk
                  ,mis = dat3$mis
                  ,buy = dat3$buy
                  ,eng = dat3$eng
                  ,dat3[,c(351:369)])


dat3_adt <- na.omit(dat3_adt)

dat3_gdn <- cbind(gdn_s = dat3$gdn_s
                  ,var_tx_tern
                  ,var_tx_sgnsq
                  ,var_tx_sgnsqrt
                  ,var_tx_lin
                  ,dat3[,c(370:388)]
                  ,rec = dat3$rec
                  ,wrk = dat3$wrk
                  ,mis = dat3$mis
                  ,buy = dat3$buy
                  ,eng = dat3$eng
                  ,dat3[,c(351:369)])


dat3_gdn <- na.omit(dat3_gdn)

dat3_emc <- cbind(emc_s = dat3$emc_s
                  ,var_tx_tern
                  ,var_tx_sgnsq
                  ,var_tx_sgnsqrt
                  ,var_tx_lin
                  ,dat3[,c(370:388)]
                  ,rec = dat3$rec
                  ,wrk = dat3$wrk
                  ,mis = dat3$mis
                  ,buy = dat3$buy
                  ,eng = dat3$eng
                  ,dat3[,c(351:369)])


dat3_emc <- na.omit(dat3_emc)
```


```{r deal_with_engagement_reu, cache=TRUE}
#Which engagement variables to use?

source('eval_measure_glm.R')

varlist <- names(dat3_reu[,c(2:length(names(dat3_reu)))])

eng_reu <- eval_measure_glm(y = "reu_s", varlist = varlist, dat = dat3_reu, iter = 100)

eng_reu$good_prediction <- ifelse(eng_reu$avg_prp_cor_hi > eng_reu$thresh_hi & eng_reu$avg_prp_cor_lo > eng_reu$thresh_lo
                                  ,1,0)

eng_reu$sig <- ifelse(eng_reu$pvalue < .05
                                  ,1,0)

eng_reu[eng_reu$good_prediction == 1 & eng_reu$sig == 1,]

```


```{r deal_with_engagement_adt, cache=TRUE}
#Which engagement variables to use?

source('eval_measure_glm.R')

varlist <- names(dat3_adt[,c(2:length(names(dat3_adt)))])

eng_adt <- eval_measure_glm(y = "adt_s", varlist = varlist, dat = dat3_adt, iter = 100)

eng_adt$good_prediction <- ifelse(eng_adt$avg_prp_cor_hi > eng_adt$thresh_hi & eng_adt$avg_prp_cor_lo > eng_adt$thresh_lo
                                  ,1,0)

eng_adt$sig <- ifelse(eng_adt$pvalue < .05
                                  ,1,0)

eng_adt[eng_adt$good_prediction == 1 & eng_adt$sig == 1,]
```

```{r deal_with_engagement_gdn, cache=TRUE}
#Which engagement variables to use?

source('eval_measure_glm.R')

varlist <- names(dat3_gdn[,c(2:length(names(dat3_gdn)))])

eng_gdn <- eval_measure_glm(y = "gdn_s", varlist = varlist, dat = dat3_gdn, iter = 100)

eng_gdn$good_prediction <- ifelse(eng_gdn$avg_prp_cor_hi > eng_gdn$thresh_hi & eng_gdn$avg_prp_cor_lo > eng_gdn$thresh_lo
                                  ,1,0)

eng_gdn$sig <- ifelse(eng_gdn$pvalue < .05
                                  ,1,0)

eng_gdn[eng_gdn$good_prediction == 1 & eng_gdn$sig == 1,]
```

```{r deal_with_engagement_emc, cache=TRUE}
#Which engagement variables to use?

source('eval_measure_glm.R')

varlist <- names(dat3_emc[,c(2:length(names(dat3_emc)))])

eng_emc <- eval_measure_glm(y = "emc_s", varlist = varlist, dat = dat3_emc, iter = 100)

eng_emc$good_prediction <- ifelse(eng_emc$avg_prp_cor_hi > eng_emc$thresh_hi & eng_emc$avg_prp_cor_lo > eng_emc$thresh_lo
                                  ,1,0)

eng_emc$sig <- ifelse(eng_emc$pvalue < .05
                                  ,1,0)

eng_emc[eng_emc$good_prediction == 1 & eng_emc$sig == 1,]
```

Engagement items were only able to significantly and reliably predict reunification as an outcome in our binomial corss-validation process. 

If more than one transformation of an engagement item was identified as a significant and reliable predictor, the item producing the minimum log-likelihood was selected. 

This resulted in the following 7 items being selected for inclusion in the BMA

1. y5_signsq "It's hard for me to work with my assigned worker" (Reverse Coded)
2. y6_signsq "Anything I say they're going to turn it around to make me look bad" (Reverse Coded)
3. y9_tern "I think my worker and I respect each other"
4. y10_tern "My worker keeps me informed about what is happening with my case"
5. y11_signsq "My worker and I agree about what's best for my child(ren)"
6. y16_signsq "My worker doesn't understand where I'm coming from at all" (Reverse Coded)
7. y19_signsq "My worker is helping me plan so I can prevent problems in the future"


```{r bma_stuff}
library(mlogitBMA)

dat3$outcome_rl_num <- as.numeric(dat3$outcome_rl)

dat3 <- cbind(dat3
              ,var_tx_tern
              ,var_tx_sgnsq
              ,var_tx_sgnsqrt
              ,var_tx_lin)


# var_tx_all <- cbind(var_tx_lin
#                     ,var_tx_sgnsq
#                     ,var_tx_sgnsqrt
#                     ,var_tx_tern
#                     ,reu_s = dat3$reu_s
#                     ,adt_s = dat3$adt_s
#                     ,gdn_s = dat3$gdn_s
#                     ,emc_s = dat3$emc_s)
# 
# dat3_eng_naom <- na.omit(var_tx_all)

dat3_naom <- dat3[,c("outcome_rl_num"
                      ,"emc_s"
                      ,"reu_s"
                      ,"adt_s"
                      ,"gdn_s"
                      ,"log_age_eps_begin"
                      ,"non_min"
                      ,"male"
                      ,"par_age"
                      ,"married"
                      ,"hhnum_c"
                      ,"rel_plc"
                      ,"log_eps_rank"
                      ,"housing_hs_cnt"
                      ,"high_in"
                      ,"sm_coll"
                      ,"employ"
                      ,"y5_signsq"
                      ,"y6_signsq"
                      ,"y9_signsq"
                      ,"y10_tern"
                      ,"y11_signsq"
                      ,"y16_signsq"
                      ,"y19_signsq")]

dat3_naom <- na.omit(dat3_naom)

glm(emc_s~.-reu_s-adt_s-gdn_s, data = dat3_eng_naom, family="binomial")

m1.emc <- bic.glm(emc_s ~ #child char
                          log_age_eps_begin +
                          non_min +
                          male +
                          #parent char
                          par_age +
                          married +
                          hhnum_c +
                          rel_plc +
                          log_eps_rank +
                          housing_hs_cnt +
                          high_in +
                          sm_coll +
                          employ +
                          y5_signsq 
#                           y6_signsq +
#                           y9_signsq +
#                           y10_tern +
#                           y11_signsq +
#                           y16_signsq +
#                           y19_signsq
                      ,data = dat3_naom
                      ,glm.family = "binomial")

summary(m1.emc)
imageplot.bma(m1.emc)

m1.adt <- bic.glm(adt_s ~ #child char
                          log_age_eps_begin +
                          non_min +
                          male +
                          #parent char
                          par_age +
                          married +
                          hhnum_c +
                          rel_plc +
                          log_eps_rank +
                          housing_hs_cnt +
                          high_in +
                          sm_coll +
                          employ +
                          y5 
#                           y6_signsq +
#                           y9_signsq +
#                           y10_tern +
#                           y11_signsq +
#                           y16_signsq +
#                           y19_signsq
                      ,data = dat3_naom
                      ,glm.family = "binomial")

summary(m1.adt)
imageplot.bma(m1.adt)

m1.gdn <- bic.glm(gdn_s ~ #child char
                          log_age_eps_begin +
                          non_min +
                          male +
                          #parent char
                          par_age +
                          married +
                          hhnum_c +
                          rel_plc +
                          log_eps_rank +
                          housing_hs_cnt +
                          high_in +
                          sm_coll +
                          employ +
                          y5_signsq 
#                           y6_signsq +
#                           y9_signsq +
#                           y10_tern +
#                           y11_signsq +
#                           y16_signsq +
#                           y19_signsq
                      ,data = dat3_naom
                      ,glm.family = "binomial")

summary(m1.gdn)
imageplot.bma(m1.gdn)

m1.reu <- bic.glm(reu_s ~ #child char
                          log_age_eps_begin +
                          non_min +
                          male +
                          #parent char
                          par_age +
                          married +
                          hhnum_c +
                          rel_plc +
                          log_eps_rank +
                          housing_hs_cnt +
                          high_in +
                          sm_coll +
                          employ +
                          y5_signsq 
                          
#                           y6_signsq +
#                           y9_signsq +
#                           y10_tern +
#                           y11_signsq +
#                           y16_signsq +
#                           y19_signsq
                      ,data = dat3_naom
                      ,glm.family = "binomial")

summary(m1.reu)
imageplot.bma(m1.reu)

model <- multinom(outcome_rl ~ age_eps_begin + 
                   eps_rank 
                 ,data = dat3
                 ,Hess = TRUE)

m1 <- multinom(outcome_rl ~ #child char
                                  log_age_eps_begin +
                                  #parent char
                                  par_age +
                                  #log_par_age +
                                  married +
                                  hhnum_c +
                                  rel_plc +
                                  housing_hs_cnt +
                                  high_in +
                                  sm_coll +
                                  employ +
                                  #y15_tern
                                  #y5
                                 y6_signsq +
                                 y11_signsq +
                                 y19_signsq
                           ,data = dat3
                           ,Hess = TRUE)
summary(m1)

z <- summary(m1)$coefficients/summary(m1)$standard.errors
p <- (1 - pnorm(abs(z), 0, 1)) * 2



m1_new_data <- data.frame(log_age_eps_begin = mean(dat3$log_age_eps_begin)
                          ,par_age = mean(dat3$par_age)
                          ,married = mean(dat3$married)
                          ,hhnum_c = mean(dat3$hhnum_c)
                          ,rel_plc = mean(dat3$rel_plc)
                          ,housing_hs_cnt = mean(dat3$housing_hs_cnt)
                          ,high_in = mean(dat3$high_in, na.rm = TRUE)
                          ,sm_coll = mean(dat3$sm_coll, na.rm = TRUE)
                          ,employ = mean(dat3$employ)
                          ,housing_hs_cnt = mean(dat3$housing_hs_cnt)
                          #,y19_signsq = mean(dat3$y19_signsq, na.rm = TRUE)
                          ,y11_signsq = c(-4, -1, 0, 1, 4)                          
                          #,y19_signsq = mean(dat3$y19_signsq, na.rm = TRUE)
                          ,y6_signsq = mean(dat3$y6_signsq))

predict(m1, newdata = m1_new_data, type = "probs", se = TRUE)



#extract params
pe <- m1$wts[c(16:28,30:42,44:56)]

#run the multinomial model
vc <- solve(m1$Hess) 

#load a package which contains a multivariate normal 
#sampling function
require(MASS)
#assign a variable for the number of simulations
sims <- 10000
#draw the indicates number of beta simulates 
#using our extracted model data
simbetas <- mvrnorm(sims,pe,vc)

simb <- array(NA, dim = c(sims,13,3))
simb[,,1] <- simbetas[,1:13]         
simb[,,2] <- simbetas[,14:26]
simb[,,3] <- simbetas[,27:39]

agerange <- seq(0,2.89,by=0.01)    

require(simcf)
require(MASS)
xhyp <- cfFactorial(log_age_eps_begin = agerange
                    ,par_age = mean(dat3$par_age)
                    ,married = mean(dat3$married)
                    ,hhnum_c = mean(dat3$hhnum_c)
                    ,rel_plc = mean(dat3$rel_plc)
                    ,housing_hs_cnt = mean(dat3$housing_hs_cnt)
                    ,high_in = mean(dat3$high_in, na.rm = TRUE)
                    ,sm_coll = mean(dat3$sm_coll, na.rm = TRUE)
                    ,employ = mean(dat3$employ)
                    ,y19_signsq = mean(dat3$y19_signsq, na.rm = TRUE)
                    ,y11_signsq = mean(dat3$y11_signsq, na.rm = TRUE)                          
                    #,y19_signsq = mean(dat3$y19_signsq, na.rm = TRUE)
                    ,y6_signsq = mean(dat3$y6_signsq))   
                    

test_sims <- mlogitsimev(xhyp,simb,ci=0.95,constant=1)

y <- as.vector(test_sims$pe[,1:4])

x <- rep(1:length(agerange), 4)

lower <- as.vector(test_sims$lower[,1:4,])

upper <- as.vector(test_sims$upper[,1:4,])

Outcome <- c(rep("Adoption", length(agerange))
                 ,rep("Guardianship"
                      ,length(agerange))
                 ,rep("Reunification"
                      ,length(agerange))
                 ,rep("Emancipation"
                      ,length(agerange)))

dat_sim_plot <- data.frame(y,x,lower,upper,Outcome)

p3 <- ggplot(dat_sim_plot
       ,aes(x=exp(x), y=y, group=Outcome)) + 
        geom_line(size=1, alpha=.5) +
        geom_ribbon(aes(ymin=lower
                        ,ymax=upper
                        ,fill=Outcome), alpha=.5) +
        ylab("Pr(Outcome|Age,Prior Episodes)") +
        xlab("Age at Entry into Foster Care") +
        scale_x_log10() +
        theme_bw() 

p3


y6_range <- seq(-4,4,by=0.1)    

xhyp[[1]]$y6_signsq <- mean(dat3$y6_signsq)
xhyp[[1]]$y11_signsq <- seq(-4,4,by=8/289)

xhyp[[2]]$y6_signsq <- mean(dat3$y6_signsq)
xhyp[[2]]$y11_signsq <- seq(-4,4,by=8/289)


test_sims <- mlogitsimev(xhyp,simb,ci=0.95,constant=1)

 
```


### Potential Covariates
We now turn to a potential set of covariates to be included with our multivariate model. In our original SSWR paper, the authors had identified a handful of covariates for inclusion in our analysis. However, given our linkage to additional variables and given the fact that we are now examining multiple competing permanency outcomes, it makes sense to expand our universe of potential covariates. 

#### Defining Covariates
As collected in the survey, some of our data are not ready for analysis. In this section, we will examine each covariate and prepare it for analysis in our event-history model. 

##### Engagement

In our original SSWR analysis, the most problematic variable that we encountered was our engagement variable. Our survey included all items from the client-engagement scale originally developed by `r citet("10.1177/1049731504271605")`. Specifically, Yatchmenoff estimated a second-order factor model in which four underlying first-order factors (i.e. receptivity, buy-in, working relationship, and mistrust) were all theorized to predict a second-order factor of engagement. In our original analysis, we simply calculated the mean of the 19 Likert-scale items and added the single term to our model. The problem with this approach is that Likert-scale items are not designed to be averaged. While a detailed discussion of this approach is beyond the scope of this analysis, several (unrealistic) assumptions must be met in order to utilize Likert scale items in this manner. In our case, we ask respondents to answer on each item on a five-point scale of "strongly agree (1)", "agree (2)", "not sure (3)", "disagree (4)", and "strongly disagree (5)". Taking an average of these values relies on an assumption that a subject's perceived distance between "strongly agree" and "agree" is the same as their perceived distance from "agree" to "not sure". Perhaps more problematically, it also relies on an assumption that the perceived distance between "strongly disagree" and "disagree" is two times greater than the distance between "strongly disagree" and "not sure". 

When used as a covariate in analysis, there are simple approaches which can be utilized to include individual Likert-scale items as covariates in an analysis. One such approach is the $2\sigma$ scaling approach advocated by `r citet("10.1002/sim.3107")`. This simply involves scaling all items included in an analysis by two standard deviations. The end result of this technique is effectively a centered variable. We could also expand the variables into a series of contrast-coded variables. The problem with both of these techniques for our current problem is that engagement is thought to be a second-order factor of all 19 items. While scaling and contrast coding provide a means through which we could enter one or many of these items into our model individually, this method does not provide us a means through which we can combine the measurements.  

One potential solution to the problem above is to estimate the structural model proposed by `r citet("10.1002/sim.3107")`, generate factor scores from her model, and then enter the factor scores into our model. This general approach is frequently utilized by researchers and specifically acknowledged by `r citet(regbib[[1]])` in his presentation of the `ltm` package `r citep(packbib[[13]])`. The `ltm` packages estimate latent variable models under an item-response-theory (IRT) approach. IRT makes none of the assumptions that are identified in the previous paragraph. Rather, IRT treats the location parameter of an IRT model as the location of the item functioning along a particular scale (or subscale).

While IRT models typically handle binary manifest variables, the general approach extends to ordinal data by way of the graded response model (GRM). Originally developed by `r citet("10.1007/BF02290599")`, the GRM defines the probability of the $i_{th}$ subject endorsing one of $m$ responses on the $j_{th}$ survey item as 

$$
  \begin{aligned}
  P(x_{jk}=m|z_i) = g(\eta_{jm}-g(\eta_{i,m+1}), \\
  \eta_{jm} = \alpha_i(z_i-\beta_{jm}), m \in \{1,2,3,4,5\}
  \end{aligned}
$$

where $x_{jk}$ is one of our 19 survey items 5 possible response categories and $z_i$ is the standing of the $i$th subject in the latent engagement scale. The other parameters measure discrimination $(\alpha)$ and extremity $(\beta)$ and are not the focus of this analysis. These components can be useful in refining a measurement instrument. Here, however, we except the basic factor structure proposed by `r citet("10.1177/1049731504271605")` but estimate our factor scores via IRT as opposed to confirmatory factor analysis^3^.

Rather than estimating engagement with all 19 survey items (estimating second-order factors in IRT is a non-trivial matter), we estimate the four first-order factors mentioned above. This is accomplished using the `ltm` package of `r citet(packbib[[12]])` and the `grm()` function and associated methods. The following specific steps are undertaken: 

1. Define two vectors of levels (one forward and one reverse) to convert the engagement items to a class of `factor`. 
2. Subset `dat3` to four data frames containing only measurements for first-order factors. 
3. Estimate IRT models for each factor with `grm()`.
4. Estimate factor scores for each response pattern with `factor.scores()`.
5. Set the `NA` values in response patterns to `-99` so we have something to join to.
6. Add the new engagement factors to `dat3` using the `sqldf` package and function from `r citet(packbib[[12]])`.

```{r prep_dat_for_eng, tidy=FALSE, cache=TRUE}
f_levels=c("1", "2", "3","4","5","-99")
f_levels_r=c("5", "4", "3","2","1","-99")

dat3$y2 = factor(ifelse(dat3$YENG2 < 1, NA, dat3$YENG2), levels=c(f_levels))
dat3$y3 = factor(ifelse(dat3$YENG3 < 1, NA, dat3$YENG3), levels=c(f_levels_r))
dat3$y7 = factor(ifelse(dat3$YENG7 < 1, NA, dat3$YENG7), levels=c(f_levels))
dat3$y15 = factor(ifelse(dat3$YENG15 < 1, NA, dat3$YENG15), levels=c(f_levels))
dat3$y5 = factor(ifelse(dat3$YENG5 < 1, NA, dat3$YENG5), levels=c(f_levels_r))
dat3$y9 = factor(ifelse(dat3$YENG9 < 1, NA, dat3$YENG9), levels=c(f_levels))
dat3$y11 = factor(ifelse(dat3$YENG11 < 1, NA, dat3$YENG11), levels=c(f_levels))
dat3$y16 = factor(ifelse(dat3$YENG16 < 1, NA, dat3$YENG16), levels=c(f_levels_r))
dat3$y6 = factor(ifelse(dat3$YENG6 < 1, NA, dat3$YENG6), levels=c(f_levels_r))
dat3$y12 = factor(ifelse(dat3$YENG12 < 1, NA, dat3$YENG12), levels=c(f_levels))
dat3$y19 = factor(ifelse(dat3$YENG18 < 1, NA, dat3$YENG18), levels=c(f_levels))
dat3$y1 = factor(ifelse(dat3$YENG1 < 1, NA, dat3$YENG1), levels=c(f_levels))
dat3$y4 = factor(ifelse(dat3$YENG4 < 1, NA, dat3$YENG4), levels=c(f_levels))
dat3$y8 = factor(ifelse(dat3$YENG8 < 1, NA, dat3$YENG8), levels=c(f_levels))
dat3$y10 = factor(ifelse(dat3$YENG10 < 1, NA, dat3$YENG10), levels=c(f_levels))
dat3$y13 = factor(ifelse(dat3$YENG13 < 1, NA, dat3$YENG13), levels=c(f_levels))
dat3$y14 = factor(ifelse(dat3$YENG14 < 1, NA, dat3$YENG14), levels=c(f_levels))
dat3$y17 = factor(ifelse(dat3$YENG19 < 1, NA, dat3$YENG19), levels=c(f_levels))
dat3$y18 = factor(ifelse(dat3$YENG17 < 1, NA, dat3$YENG17), levels=c(f_levels))

eng_rec <- subset(dat3,select = c(DCID, y2, y3, y7, y15))
eng_wrk <- subset(dat3,select = c(DCID, y5, y9, y11, y16))
eng_mis <- subset(dat3,select = c(DCID, y6, y12, y19))
eng_buy <- subset(dat3,select = c(DCID, y1, y4, y8, y10, y13, y14, y17, y18))

fit_rec <- grm(eng_rec[,2:5], Hessian=TRUE)
fit_wrk <- grm(eng_wrk[,2:5], Hessian=TRUE)
fit_mis <- grm(eng_mis[,2:4], Hessian=TRUE)
fit_buy <- grm(eng_buy[,2:9], Hessian=TRUE)

scor_rec <- factor.scores(fit_rec, method="EAP")$score.dat
scor_wrk <- factor.scores(fit_wrk, method="EAP")$score.dat
scor_mis <- factor.scores(fit_mis, method="EAP")$score.dat
scor_buy <- factor.scores(fit_buy, method="EAP")$score.dat

#reassign NA values as negative -99 so we don't loose them in the joins we perform below...
scor_wrk[is.na(scor_wrk)] <- -99
scor_rec[is.na(scor_rec)] <- -99
scor_mis[is.na(scor_mis)] <- -99
scor_buy[is.na(scor_buy)] <- -99

dat3$y2[is.na(dat3$y2)] <- -99
dat3$y3[is.na(dat3$y3)] <- -99
dat3$y7[is.na(dat3$y7)] <- -99
dat3$y15[is.na(dat3$y15)] <- -99
dat3$y5[is.na(dat3$y5)] <- -99
dat3$y9[is.na(dat3$y9)] <- -99
dat3$y11[is.na(dat3$y11)] <- -99
dat3$y16[is.na(dat3$y16)] <- -99
dat3$y6[is.na(dat3$y6)] <- -99
dat3$y12[is.na(dat3$y12)] <- -99
dat3$y19[is.na(dat3$y19)] <- -99
dat3$y1[is.na(dat3$y1)] <- -99
dat3$y4[is.na(dat3$y4)] <- -99
dat3$y8[is.na(dat3$y8)] <- -99
dat3$y10[is.na(dat3$y10)] <- -99
dat3$y13[is.na(dat3$y13)] <- -99
dat3$y14[is.na(dat3$y14)] <- -99
dat3$y17[is.na(dat3$y17)] <- -99
dat3$y18[is.na(dat3$y18)] <- -99

dat3$y2 <- as.numeric(dat3$y2)
dat3$y3 <- as.numeric(dat3$y3)
dat3$y7 <- as.numeric(dat3$y7)
dat3$y15 <- as.numeric(dat3$y15)
dat3$y5 <- as.numeric(dat3$y5)
dat3$y9 <- as.numeric(dat3$y9)
dat3$y11 <- as.numeric(dat3$y11)
dat3$y16 <- as.numeric(dat3$y16)
dat3$y6 <- as.numeric(dat3$y6)
dat3$y12 <- as.numeric(dat3$y12)
dat3$y19 <- as.numeric(dat3$y19)
dat3$y1 <- as.numeric(dat3$y1)
dat3$y4 <- as.numeric(dat3$y4)
dat3$y8 <- as.numeric(dat3$y8)
dat3$y10 <- as.numeric(dat3$y10)
dat3$y13 <- as.numeric(dat3$y13)
dat3$y14 <- as.numeric(dat3$y14)
dat3$y17 <- as.numeric(dat3$y17)
dat3$y18 <- as.numeric(dat3$y18)

dat3 <- sqldf("select d3.*
                  ,sw.z1 wrk_z
                  ,sr.z1 rec_z
                  ,sm.z1 mis_z
                  ,sb.z1 buy_z
                from dat3 d3
                  left join scor_wrk sw
                    on ifnull(d3.y5,-99) = sw.y5
                      and ifnull(d3.y9,-99) = sw.y9
                      and ifnull(d3.y11,-99) = sw.y11
                      and ifnull(d3.y16,-99) = sw.y16
                  left join scor_rec sr
                    on ifnull(d3.y2,-99) = sr.y2
                      and ifnull(d3.y3,-99) = sr.y3
                      and ifnull(d3.y7,-99) = sr.y7
                      and ifnull(d3.y15,-99) = sr.y15
                  left join scor_mis sm
                    on ifnull(d3.y6,-99) = sm.y6
                      and ifnull(d3.y12,-99) = sm.y12
                      and ifnull(d3.y19,-99) = sm.y19
                  left join scor_buy sb
                    on d3.y1 = sb.y1
                      and ifnull(d3.y4,-99) = sb.y4
                      and ifnull(d3.y8,-99) = sb.y8
                      and ifnull(d3.y10,-99) = sb.y10
                      and ifnull(d3.y13,-99)= sb.y13
                      and ifnull(d3.y14,-99) = sb.y14
                      and ifnull(d3.y17,-99) = sb.y17
                      and ifnull(d3.y18,-99) = sb.y18")
```

We next examine the correlation of the factor scores (and an overall mean of the scores) with the difference between interview dates and the overall length of stay. Correlation between engagement and the proximity of interview to the end of an episode was a significant problem in the original SSWR study. 

```{r examine_eng_cor, cache=TRUE}
cor(dat3$wrk_z, dat3$time_to_int-dat3$reu_t, use="comp")
cor(dat3$rec_z, dat3$time_to_int-dat3$reu_t, use="comp")
cor(dat3$mis_z, dat3$time_to_int-dat3$reu_t, use="comp")
cor(dat3$buy_z, dat3$time_to_int-dat3$reu_t, use="comp")

dat3$m_eng <- (dat3$wrk_z + dat3$rec_z + dat3$mis_z + dat3$buy_z)/4
cor(dat3$m_eng, dat3$time_to_int-dat3$reu_t, use="comp")
```

The measure of working relationship (`wrk_z`) has a relatively strong association with interview proximity to permanency and should be excluded from our analysis. The mean engagement score (`m_eng`) and mistrust score (`mis_z`) have a weak association with proximity and will also be excluded at this time. Receptivity (`rec_z`) and buy-in (`buy_z`) appear to have no substantive association with time and will both be included with our analysis.

##### Child Age at Removal

Define a log scaled age variable (`log_age_eps_begin`) and a flag indicating that the child is an adolescent (`ad_child`) and another indicating that they are a toddler (`sm_child`)

```{r define_child_age, cache=TRUE}
dat3$log_age_eps_begin <- log1p(dat3$age_eps_begin)
dat3$ad_chld <- ifelse(dat3$age_eps_begin > 11, 1, 0)  
dat3$sm_chld <- ifelse(dat3$age_eps_begin <= 3, 1, 0) 
```

##### Child Race

Define a flag to indicate whether or not a child is a non-minority (`non_min`).

```{r define_child_race, cache=TRUE}
dat3$non_min <- ifelse(dat3$cd_race_census == 5, 1, 0)
```

##### Socio-Economic Factors

Define a count of housing hardships (`housing_hs_cnt`), a flag to indicate whether or not the parent has experienced any housing hardship during the past year (`hsg_hds`), a flag for income above 10,000 dollars (`high_in`), a flag for whether or not a parent has any college (`sm_coll`), and a flag indicating whether or not the parent is employed (`employ`). 

```{r define_ses, cache=TRUE}
dat3$housing_hs_cnt <- ifelse(is.na(dat3$LACRENT) == TRUE | dat3$LACRENT == 2, 0, 1) +
                        ifelse(is.na(dat3$EVICT) == TRUE | dat3$EVICT == 2, 0, 1) + 
                        ifelse(is.na(dat3$FAMFRND) == TRUE | dat3$FAMFRND == 2, 0, 1) + 
                        ifelse(is.na(dat3$REPOSS) == TRUE | dat3$REPOSS == 2, 0, 1) + 
                        ifelse(is.na(dat3$HOMLSS) == TRUE | dat3$HOMLSS == 2, 0, 1) 
dat3$hsg_hds <- ifelse(dat3$housing_hs_cnt > 0, 1, 0)
dat3$high_in <- ifelse(dat3$THHINC < 1, NA, ifelse(dat3$THHINC > 1, 1, 0))
dat3$sm_coll <- ifelse(dat3$EDULVL < 1, NA, ifelse(dat3$EDULVL > 3, 1, 0))
dat3$employ <- ifelse(dat3$EMPSTAT < 1, NA, ifelse(dat3$EMPSTAT != 1, 1, 0))
```

##### Parental and Household Demographics

Define a count of demographic variables associated with the house and/or parents including gender (`male`), parental age and the associate log transform (`par_age` and `log_par_age`), a flag to indicate whether or not the parent is married (`married`), and the number of children in the household (`hhnum_c`). 

```{r define_par_demo, cache=TRUE}
dat3$male <- ifelse(dat3$cd_gndr == "M", 1, 0)
dat3$par_age <- year(strptime(dat3$eps_begin, format = "%Y-%m-%d"))-year(strptime(dat3$DOB, format = "%Y-%m-%d"))
dat3$log_par_age <- log(dat3$par_age)
dat3$married <- ifelse(dat3$MARSTAT < 1, NA, ifelse(dat3$MARSTAT == 2, 1, 0))
dat3$hhnum_c <- ifelse(dat3$CHTOTNUM < 1, NA, dat3$CHTOTNUM)
```


##### Case Characteristics

Define a flag for relative placement (`rel_plc`), the count of previous episodes and the associated log transform (`eps_rank`) and (`log_eps_rank`). 

```{r casechar, cache=TRUE}
dat3$rel_plc <- ifelse(as.numeric(dat3$longest_plcm_setng)==3,1,0)
dat3$eps_rank <- dat3$eps_rank
dat3$log_eps_rank <- log(dat3$eps_rank)
```

#### Examine a Summary of Covariates

The identified covariates are displayed in the following table along with summary descriptive statistics. 

```{r subset_descriptives, include=FALSE, cache=TRUE}
x <- dat3[,c("log_age_eps_begin"
              ,"age_eps_begin"
              ,"non_min" 
              ,"ad_chld"
              ,"sm_chld" 
              ,"housing_hs_cnt"
              ,"hsg_hds"
              ,"high_in"
              ,"sm_coll"
              ,"employ"
              ,"par_age"
              ,"log_par_age"
              ,"married"
              ,"hhnum_c"
              ,"rel_plc"
              ,"log_eps_rank"
              ,"buy_z"
              ,"rec_z"
              )] 
```

```{r display_descriptives, results='asis', cache=TRUE}

pander(summary(x), split.table="Inf")

```

# Building Our Models

## Define a Function for Calculating the Predicted Subdensity

```{r subdensity_function, cache=TRUE}
cuminc_cr <- function(mod1=mr, mod2=mr_cr, strata=1, time=time){
  
  h1 <- rep(NA, time)
  for(i in 1:time){
    h1[i] <- hazard(i, mod1)[strata]
  }
  s1 <- rep(NA, time)
  for(i in 1:time){
    s1[i] <- survival(i, mod1)[strata]
  }
  s2 <- rep(NA, time)
  for(i in 1:time){
      s2[i] <- survival(i, mod2)[strata]
  }
  #pdf for event 1
  f1 <- (1-s1) + h1
  #subdensity for event 1
  f1s <- f1*s2
    return(f1s)
}
```


## Process for Building Models

For each outcome: 

1. Identify covariates via BMA, 
2. Build model with covariates using `frailtypack` clustering on `DCID`, and 
3. Simulate subdensities using the `cuminc_cr` function defined above. 

```{r begin_modeling, cache=TRUE, warning=FALSE, message=FALSE}
require(frailtypack)
require(BMA)
require(survival)

dat3$crt_t_mod <- dat3$crt_t + 1
dat3$reu_t_mod <- dat3$reu_t + 1
dat3$adt_t_mod <- dat3$adt_t + 1
dat3$gdn_t_mod <- dat3$gdn_t + 1

#dat3_na <- na.omit(dat3)

x <- dat3[,c("log_age_eps_begin"
              ,"age_eps_begin"
              ,"non_min" 
              ,"ad_chld"
              ,"sm_chld" 
              ,"housing_hs_cnt"
              ,"hsg_hds"
              ,"high_in"
              ,"sm_coll"
              ,"employ"
              ,"par_age"
              ,"log_par_age"
              ,"married"
              ,"hhnum_c"
              ,"rel_plc"
              ,"log_eps_rank"
              ,"buy_z"
              ,"rec_z"
              )] 

```


### Build Reunification Model

```{r Build_Reunification_Model, cache=TRUE, warning=FALSE, message=FALSE}
mr_bic <- bic.surv(as.data.frame(x), dat3$reu_t_mod, dat3$reu_s)
#summary(mr_bic)

mr <- frailtyPenal(Surv(reu_t_mod, reu_s) ~ 
                                        cluster(DCID) +
                                        ad_chld +
                                        hsg_hds +
                                        sm_coll +
                                        employ +
                                        par_age +
                                        married +
                                        rel_plc +
                                        buy_z +
                                        strata(ifelse(REG==1|REG==2, 1, 0))
                                ,n.knots = 10
                                ,kappa1 = 2.11e+08
                                ,kappa2 = 2.11e+08
                                #,hazard = "Weibull"
                                ,data = dat3)

#plot(mr, type="s")



mr_cr <- frailtyPenal(Surv(reu_t_mod, dat3$gdn_s+dat3$adt_s) ~ 
                                        cluster(DCID) +
                                        ad_chld +
                                        hsg_hds +
                                        sm_coll +
                                        employ +
                                        par_age +
                                        married +
                                        rel_plc +
                                        buy_z +
                                        strata(ifelse(REG==1|REG==2, 1, 0))
                                ,n.knots = 10
                                ,kappa1 = 2.11e+08
                                ,kappa2 = 2.11e+08
                                #,hazard = "Weibull"
                                ,data = dat3)

freu <- cuminc_cr(mr, mr_cr, time=max(dat3$reu_t))
```

### Reunification Estimates

```{r display_reunification_estimates, cache=TRUE, warning=FALSE, message=FALSE}
summary(mr)

# frail_tiles_r <- quantile(mr$frailty.pred, c(.05, .50, .95)) 
# frail_tiles_cr <- quantile(mr_cr$frailty.pred, c(.05, .50, .95)) 
```


### Build Adoption Model

```{r Build_Adoption_Model, cache=TRUE, warning=FALSE, message=FALSE}
ma_bic <- bic.surv(as.data.frame(x), dat3$adt_t_mod, dat3$adt_s)
#summary(ma_bic)


ma <- frailtyPenal(Surv(adt_t_mod, adt_s) ~ 
                                        cluster(DCID) +
                                        ad_chld +
                                        non_min +
                                        rec_z +
                                        strata(ifelse(REG==1|REG==2, 1, 0))
                                ,n.knots = 10
                                ,kappa1 = 2.11e+08
                                ,kappa2 = 2.11e+08
                                ,data = dat3)
ma_cr <- frailtyPenal(Surv(adt_t_mod, adt_s+gdn_s) ~ 
                                        cluster(DCID) +
                                        ad_chld +
                                        non_min +
                                        rec_z +
                                        strata(ifelse(REG==1|REG==2, 1, 0))
                                ,n.knots = 10
                                ,kappa1 = 2.11e+08
                                ,kappa2 = 2.11e+08
                                ,data = dat3)
#summary(ma_cr)
fadt <- cuminc_cr(ma, ma_cr, time=max(dat3$adt_t))
```

### Adoption Estimates

```{r display_adoption_estimates, cache=TRUE, warning=FALSE, message=FALSE}

summary(ma)
```

### Build Guardianship Model

```{r Build_Guardianship_Model, cache=TRUE, warning=FALSE, message=FALSE}

mg_bic <- bic.surv(as.data.frame(x), dat3$gdn_t_mod, dat3$gdn_s)
#summary(mg_bic)


mg <- frailtyPenal(Surv(gdn_t_mod, gdn_s) ~ 
                                        cluster(DCID) +
                                        ad_chld +
                                        employ +
                                        rel_plc +
                                        strata(ifelse(REG==1|REG==2, 1, 0))
                                ,n.knots = 10
                                ,kappa1 = 2.11e+08
                                ,kappa2 = 2.11e+08
                                ,data = dat3)

mg_cr <- frailtyPenal(Surv(adt_t_mod, dat3$adt_s+dat3$reu_s) ~ 
                                        cluster(DCID) +
                                        ad_chld +
                                        non_min +
                                        rec_z +
                                        strata(ifelse(REG==1|REG==2, 1, 0))
                                ,n.knots = 10
                                ,kappa1 = 2.11e+08
                                ,kappa2 = 2.11e+08
                                ,data = dat3)
#summary(mg_cr)
fgdn <- cuminc_cr(mg, mg_cr, time=max(dat3$gdn_t))
```

### Guardianship Estimates

```{r display_guardianship_estimates, cache=TRUE, warning=FALSE, message=FALSE}
summary(mg)
```

## Plot Predicted Subdensities

```{r plot_subdensities, fig.width=8, fig.height=6}
require(reshape2)

dist_plot <- as.data.frame(cbind(freu, fadt, fgdn, time=seq(1:max(dat3$gdn_t))))
dist_plot_m <- melt(dist_plot, id.vars="time")
levels(dist_plot_m$variable) <- c("Reunification", "Adoption", "Guardianship")

ggplot(dist_plot_m, aes(x=time/365.25, y=value, colour=variable)) + 
  geom_line(size=1.25) +
  scale_colour_manual(values=poc_colors, name="Outcome") +
  scale_fill_manual(values=poc_colors
                    ,guide = guide_legend(title = NULL)) +
  xlab("Years in Care") +
  ylab("Subdensity of Outcome") +
  theme_bw() +
  theme(text=element_text(size=16
                          ,family="Frutiger LT Std 45 Light"))

```

# Directions to Take

## With Respect to Focus
1. General focus on inference with respect to permanency times.
2. General focus on inference with respect to permanency outcomes. 
3. Specific focus on engagement (we could unpack specific items in this measure more than we have thus far). 
4. Specific focus on aging out of foster care.  
5. Specific focus on worker characteristics (unexplored so far, but possible). 

## With Respect to Modeling
1. Write up the paper as-is with a discussion of how properly nested models may yield a smaller number of significant predictors than what has traditionally been the case. 
2. Drop the nesting feature of our current models and just bootstrap our standard errors (this will yield a larger number of significant predictors).
3. Drop our right-censored observations and just take a multinomial logistic or probit approach. 
4. Drop our right-censored observations and develop an accelerated failure time model. If our subdensities are as well-behaved as they appear to be, this might be a reasonable approach to take. We don't *need* to drop the right-censored observations to go down this road, but it would make life easier. 


# Endnotes
^1^ All tables created in this document were created using the `pander` package `r citep(packbib[11])`

^2^ The results shown here are a special case of a more general approach to calculating a probability of aging-out of the foster care system. The more general approach will be discussed in a forthcoming manuscript by Gregor Passolt. 

^3^ It should be noted that the factor structure proposed by `r citet("10.1007/BF02290599")` has never been validated with our current survey data. While it is reasonable to accept the model as presented in the literature, a future contribution to the literature should be to confirm the model and possibly take an IRT approach assessing the extent to which specific engagement items function differentially (e.g. are biased for certain race categories, etc.).

# Bibliography
```{r bibliography, results='asis'}
bibliography()
```

